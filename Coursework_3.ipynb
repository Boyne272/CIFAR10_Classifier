{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "colab_type": "code",
    "id": "LL3vQPYkhzOy",
    "outputId": "7ab27bd0-ca00-443a-8480-40b4821b9d6b"
   },
   "outputs": [],
   "source": [
    "!pip install pycm livelossplot\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "En9dBOn0hzPL"
   },
   "source": [
    "## Coursework - Training a classifier on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGURJ5EBhzPO"
   },
   "source": [
    "Your task in this coursework is to implement, train, validate and test a classifier on the CIFAR10 dataset.  \n",
    "\n",
    "Complete the following tasks:\n",
    "\n",
    "1. Use ```torchvision.datasets.CIFAR10``` to load the CIFAR10 dataset. (1 point)\n",
    "2. Plot 25 images of the training set together with their corresponding label names. (2 points)\n",
    "3. Create a (90-10) training and validation split using ```sklearn.model_selection.StratifiedShuffleSplit```  (2 points)\n",
    "4. Instantiate Datasets and Dataloader with CIFAR10, training, validation and test data.\n",
    "    - Make sure the data is adequately normalised (0-mean, 1-Standard Deviation)\n",
    "5. Modify LeNet5 from the morning exercises to be able to work with CIFAR10. (5 points)\n",
    "6. Perform a line-search over the L2-Regularization parameter, use the ```weight_decay=value``` keyword argument in the ```torch.optim``` modules (5 points).\n",
    "  - Other Hyperparameters:\n",
    "    - Random Number Seed 42\n",
    "    - Learning Rate = 1e-2\n",
    "    - Momentum = 0.5\n",
    "    - Batch Size = 64\n",
    "    - Test Batch Size = 1000\n",
    "    - Number of Epochs = 30\n",
    "    - Optimizer = SGD\n",
    " - Values of weight_decay to use in line search: ```[0.0, 1e-3, 1e-4, 1e-5]```\n",
    "7. Choose the best weight-decay value given the other hyperparameters and train on the full CIFAR10 training set (4 points).\n",
    "8. Test your final model on the test set (2 points)\n",
    "9. Store the model parameters in a ```.pth``` file (2 points).\n",
    "9. Answer the following questions (1 point each):   \n",
    "  **Which of these data-augmentation transforms would be reasonable to apply to CIFAR10 and why?   **\n",
    "  - Left-Right Flips\n",
    "  - Random Rotations by up to 10 Degrees\n",
    "  - Up-Down Flips\n",
    "  - Shifting up-down, left-right by 5 pixels\n",
    "  - Contrast Changes\n",
    "  - Adding Gaussian Noise\n",
    "  - Random Rotations by up to 90 Degrees\n",
    "\n",
    " Describe your working as comments in a Jupyter Notebook together with your code implementation and provide the final Jupyter Notebook and your trained model weights in a github repository.\n",
    " \n",
    " Total Points: 30\n",
    " \n",
    "### Final Deliverables:\n",
    "\n",
    "- Two Files in Total:\n",
    "    - Jupyter Notebook with Code and Documented Methods\n",
    "    - Model trained on the test set stored as ```CIFAR10_classifier.pth``` (use ```torch.save(model, \"CIFAR10_classifier.pth\"```)\n",
    "- Due Date: _MONDAY May 20th, 2019, 9 am_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXJ6R5CBhzPQ"
   },
   "source": [
    "#### A few imports before we get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5-tUzUV2hzPU",
    "outputId": "bd476394-ee2b-484c-c146-098a6c12134a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda installed! Running on GPU!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "from pycm import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tLRNHc8GOfR"
   },
   "source": [
    "### Mounting the google drive for later storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Dg3oP6GHGOsX",
    "outputId": "d473382e-4ad4-4753-f34f-045797c4ad9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_UioFmvFIDw"
   },
   "source": [
    "### 1. Loading CIFAR10 from torchvision.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iiKdF74ip8n"
   },
   "source": [
    "### 2. Plotting 25 examples with their class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZIKWFh11AK_Y"
   },
   "source": [
    "### 3. Instantiate and create a ```StratifiedShuffleSplit``` using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RM9owG-yAMLv"
   },
   "source": [
    "### 4. Instantiate a ```torch.utils.data.TensorDataset``` for training, validation and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZ2qMRUGAEUA"
   },
   "source": [
    "### 5. Modified LeNet5 for CIFAR10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bcFPI8XKAOtl"
   },
   "source": [
    "#### Define Train, Validation and Evaluate Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_pehihNAQ9E"
   },
   "source": [
    "#### Set the hyperparameters of your model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMEpCuC1EEFw"
   },
   "source": [
    "### 6. Perform a hyperparameter search of the Weight-Decay Parameter using the train/validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-OG3gAcE2mr"
   },
   "source": [
    "### 7. Train the model with the best weight-decay parameter according to the validation accuracy on the full training set and test it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7_Z_P15iW8S"
   },
   "source": [
    "### 8. Store the final model to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UtMMw_in7wD"
   },
   "source": [
    "### 9. Answer the following questions (1 point each):   \n",
    "  **Which of these data-augmentation transforms would be reasonable to apply to CIFAR10 and why?   **\n",
    "  - Left-Right Flips\n",
    "  - Random Rotations by up to 10 Degrees\n",
    "  - Up-Down Flips\n",
    "  - Shifting up-down, left-right by 5 pixels\n",
    "  - Contrast Changes\n",
    "  - Adding Gaussian Noise\n",
    "  - Random Rotations by up to 90 Degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Afternoon_Session_4_Coursework_CIFAR10.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
